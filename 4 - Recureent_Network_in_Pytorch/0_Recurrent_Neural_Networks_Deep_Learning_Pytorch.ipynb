{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Recurrent Neural Networks Deep Learning GRU"
      ],
      "metadata": {
        "id": "QM6ZFmduov0Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installs:"
      ],
      "metadata": {
        "id": "b-5CJXN8o2qw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nhhaRhQVR27"
      },
      "outputs": [],
      "source": [
        "# % pip install torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports:"
      ],
      "metadata": {
        "id": "Grv-hrpvouZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytorch\n",
        "import torch # Pytorch\n",
        "import torch.nn as nn # Pytorch Neural Network\n",
        "import torch.nn.functional as F # Pytorch Functional\n",
        "import torch.optim as optim # Optimizer\n",
        "\n",
        "# Numpy\n",
        "import numpy as np # Numpy\n",
        "\n",
        "# Matplotlib\n",
        "import matplotlib.pyplot as plt # Matplotlib\n",
        "\n",
        "# Unicodedata\n",
        "import unicodedata # Unicodedata\n",
        "\n",
        "# String\n",
        "import string # String\n",
        "\n",
        "# Read data\n",
        "import os as os # Os"
      ],
      "metadata": {
        "id": "kOAfzy1zpQ45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classifying names with a Character-Level RNN"
      ],
      "metadata": {
        "id": "yO-pubNaqOmu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem: Given an input proper name, classify that name according to the nationality to which it belongs. Entrance: Hinton\n",
        "\n",
        "(-0.47) Scottish\n",
        "\n",
        "(-1.52) English\n",
        "\n",
        "(-3.57) Irish\n",
        "\n",
        "-\n",
        "\n",
        "Entry: Schmidhuber\n",
        "\n",
        "(-0.19) German\n",
        "\n",
        "(-2.48) Czech\n",
        "\n",
        "(-2.68) Dutch"
      ],
      "metadata": {
        "id": "V5CkRFjQqQyL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Dataset"
      ],
      "metadata": {
        "id": "8TfiVlSuqnex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Data\n",
        "#! wget https://download.pytorch.org/tutorial/data.zip\n",
        "#! unzip data.zip\n",
        "#! ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5S7PAZ5IqHO1",
        "outputId": "3a20f0b5-0d47-4b69-d7c9-705c5a3db1bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-07 10:10:18--  https://download.pytorch.org/tutorial/data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 108.138.64.125, 108.138.64.61, 108.138.64.97, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|108.138.64.125|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘data.zip.1’\n",
            "\n",
            "\rdata.zip.1            0%[                    ]       0  --.-KB/s               \rdata.zip.1          100%[===================>]   2.75M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-05-07 10:10:18 (94.5 MB/s) - ‘data.zip.1’ saved [2882130/2882130]\n",
            "\n",
            "Archive:  data.zip\n",
            "replace data/eng-fra.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: data/eng-fra.txt        \n",
            "  inflating: data/names/Arabic.txt   \n",
            "  inflating: data/names/Chinese.txt  \n",
            "  inflating: data/names/Czech.txt    \n",
            "  inflating: data/names/Dutch.txt    \n",
            "  inflating: data/names/English.txt  \n",
            "  inflating: data/names/French.txt   \n",
            "  inflating: data/names/German.txt   \n",
            "  inflating: data/names/Greek.txt    \n",
            "  inflating: data/names/Irish.txt    \n",
            "  inflating: data/names/Italian.txt  \n",
            "  inflating: data/names/Japanese.txt  \n",
            "  inflating: data/names/Korean.txt   \n",
            "  inflating: data/names/Polish.txt   \n",
            "  inflating: data/names/Portuguese.txt  \n",
            "  inflating: data/names/Russian.txt  \n",
            "  inflating: data/names/Scottish.txt  \n",
            "  inflating: data/names/Spanish.txt  \n",
            "  inflating: data/names/Vietnamese.txt  \n",
            "data  data.zip\tdata.zip.1  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to read the file and create labels\n",
        "def read_files(file_name):\n",
        "\n",
        "    # Spliting files in lines\n",
        "    lines = open(file_name).read().strip().split('\\n')\n",
        "\n",
        "    # Normalizing data\n",
        "    names = [unicodedata.normalize('NFKD', line).encode('ascii', 'ignore') for line in lines]\n",
        "\n",
        "    # Spliting Categories\n",
        "    category = file_name.split('/')[-1].split('.')[0]\n",
        "\n",
        "    # Labels\n",
        "    labels = np.repeat(category, len(names))\n",
        "\n",
        "    # Returning\n",
        "    return names, labels"
      ],
      "metadata": {
        "id": "r-Awv1hWq7pO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining root\n",
        "root_path = 'data/names'\n",
        "files = sorted(os.listdir(root_path))\n",
        "categories = [c[: -4] for c in files]"
      ],
      "metadata": {
        "id": "TrlgbMUBtV_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Size files and categories\n",
        "len(files), len(categories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KELQrf2vT_W",
        "outputId": "e378d1da-0726-471c-c7b0-d8ae020ae95c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Categories\n",
        "categories"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X8gsJOlvcRD",
        "outputId": "ed71c721-e4f8-4e0b-d7be-ebc737f652f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Arabic',\n",
              " 'Chinese',\n",
              " 'Czech',\n",
              " 'Dutch',\n",
              " 'English',\n",
              " 'French',\n",
              " 'German',\n",
              " 'Greek',\n",
              " 'Irish',\n",
              " 'Italian',\n",
              " 'Japanese',\n",
              " 'Korean',\n",
              " 'Polish',\n",
              " 'Portuguese',\n",
              " 'Russian',\n",
              " 'Scottish',\n",
              " 'Spanish',\n",
              " 'Vietnamese']"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Files\n",
        "files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfMIkh2Lvguw",
        "outputId": "614e1b16-d66e-4a26-d024-b7c7056c94b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Arabic.txt',\n",
              " 'Chinese.txt',\n",
              " 'Czech.txt',\n",
              " 'Dutch.txt',\n",
              " 'English.txt',\n",
              " 'French.txt',\n",
              " 'German.txt',\n",
              " 'Greek.txt',\n",
              " 'Irish.txt',\n",
              " 'Italian.txt',\n",
              " 'Japanese.txt',\n",
              " 'Korean.txt',\n",
              " 'Polish.txt',\n",
              " 'Portuguese.txt',\n",
              " 'Russian.txt',\n",
              " 'Scottish.txt',\n",
              " 'Spanish.txt',\n",
              " 'Vietnamese.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Samples by class\n",
        "dataset, labels = [], []\n",
        "sample_by_class = []\n",
        "\n",
        "for filename in files:\n",
        "\n",
        "    # Return data\n",
        "    returning_data = read_files(os.path.join(root_path, filename))\n",
        "\n",
        "    # Salving data in list\n",
        "    dataset.append(returning_data[0])\n",
        "\n",
        "    # Salving label in list\n",
        "    labels.append(returning_data[1])\n",
        "\n",
        "    # Sample by class\n",
        "    sample_by_class.append( (filename, len(returning_data[0])) )"
      ],
      "metadata": {
        "id": "Pase0qxgvkYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Samples by class\n",
        "for sample_class in sample_by_class:\n",
        "    print(sample_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iPkp60tygVN",
        "outputId": "87d1d5aa-a53b-4202-f182-7b580b873568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Arabic.txt', 2000)\n",
            "('Chinese.txt', 268)\n",
            "('Czech.txt', 519)\n",
            "('Dutch.txt', 297)\n",
            "('English.txt', 3668)\n",
            "('French.txt', 277)\n",
            "('German.txt', 724)\n",
            "('Greek.txt', 203)\n",
            "('Irish.txt', 232)\n",
            "('Italian.txt', 709)\n",
            "('Japanese.txt', 991)\n",
            "('Korean.txt', 94)\n",
            "('Polish.txt', 139)\n",
            "('Portuguese.txt', 74)\n",
            "('Russian.txt', 9408)\n",
            "('Scottish.txt', 100)\n",
            "('Spanish.txt', 298)\n",
            "('Vietnamese.txt', 73)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Min sample by class\n",
        "print(f'Min sample: {min(sample_by_class, key = lambda k: k[1])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJU-zevoyxC1",
        "outputId": "8f8b1f7c-1d32-4c7e-8d67-cafee18eb569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min sample: ('Vietnamese.txt', 73)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View data\n",
        "print(dataset[categories.index('Portuguese')][0:10])\n",
        "print(labels[categories.index('Portuguese')][0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlGyBiqNzbv5",
        "outputId": "24d1cffd-8834-4fdc-cddf-7a76a31ff88b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[b'Abreu', b'Albuquerque', b'Almeida', b'Alves', b'Araujo', b'Araullo', b'Barros', b'Basurto', b'Belo', b'Cabral']\n",
            "['Portuguese' 'Portuguese' 'Portuguese' 'Portuguese' 'Portuguese'\n",
            " 'Portuguese' 'Portuguese' 'Portuguese' 'Portuguese' 'Portuguese']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting the labels to tensor"
      ],
      "metadata": {
        "id": "z_TqhsLN0V1v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One-Hot representation of 18 language categories that we want to predict."
      ],
      "metadata": {
        "id": "b0cWP1N20Zyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LabelToTensor(labels):\n",
        "\n",
        "    # Defining a tensor with values in euros with the size of the labels\n",
        "    label_tensor = torch.zeros(len(labels), 1, dtype = torch.int64)\n",
        "\n",
        "    for k, label in enumerate(labels):\n",
        "        idx = categories.index(label)\n",
        "        label_tensor[k][0] = idx\n",
        "\n",
        "    return label_tensor"
      ],
      "metadata": {
        "id": "muXqcnEsz-r0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_test = labels[0]\n",
        "tns_labels = LabelToTensor(labels_test)\n",
        "print(type(tns_labels)), labels_test[0], tns_labels[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_U4uambHrHYj",
        "outputId": "851b2f7b-82cc-407c-f45a-376c84e63534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 'Arabic', tensor([0]))"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting names to tensor"
      ],
      "metadata": {
        "id": "GVH3m7EDsK3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid_characters = string.ascii_letters\n",
        "valid_characters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "pL-6-UV0rJQz",
        "outputId": "403218f6-415e-4725-9d90-00a177b1c1c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "size_dictionary = len(valid_characters)\n",
        "size_dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJD5XUELr0dr",
        "outputId": "689c7ec4-2dec-4b45-d2ce-18f02f6a7de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def NamesToTensor(data_names):\n",
        "\n",
        "    # Defining a tensor with values in euros with the size of the Names\n",
        "    names_tensor = torch.zeros(len(data_names), size_dictionary)\n",
        "\n",
        "    for k, letter in enumerate(data_names.decode('utf-8')):\n",
        "        idx = valid_characters.find(letter)\n",
        "\n",
        "        names_tensor[k, idx] = 1\n",
        "    return names_tensor"
      ],
      "metadata": {
        "id": "G8VGWNN2urOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name_test = dataset[0]\n",
        "tsn_names = [NamesToTensor(name) for name in name_test]\n",
        "print(name_test[0].decode('utf-8')[0], ' \\n', tsn_names[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4QYTn3Cvs-l",
        "outputId": "3a68ec04-8180-4552-c024-ead7e0f4518c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K  \n",
            " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampling balanced batch"
      ],
      "metadata": {
        "id": "S7GBWc7Fzs7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the minimum number of samples according to the smallest dataset\n",
        "num_sample = min(sample_by_class, key = lambda k: k[1])[1]\n",
        "num_sample"
      ],
      "metadata": {
        "id": "kD8Edrx4vybk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fad18ff-d63b-44fd-8806-71e913aa270f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_batch(size = num_sample):\n",
        "\n",
        "    # Defining lists to store batch data\n",
        "    data_batch, label_batch = [], []\n",
        "\n",
        "    for cat in categories:\n",
        "        sample_cat = dataset[categories.index(cat)]\n",
        "        idx  = np.random.choice( range(len(sample_cat)), size = size )\n",
        "\n",
        "        # Batch's\n",
        "        data_batch.extend( [data for k, data in enumerate(dataset[categories.index(cat)]) if k in idx] )\n",
        "        label_batch.extend( [label for k, label in enumerate(labels[categories.index(cat)]) if k in idx] )\n",
        "\n",
        "    # Tranforming to Tensor's\n",
        "    data = [NamesToTensor(batch)for batch in data_batch]\n",
        "    label  =  LabelToTensor(label_batch)\n",
        "\n",
        "    # Returning\n",
        "    return data, label"
      ],
      "metadata": {
        "id": "MwsjkeLw0R6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test function\n",
        "data_batch, label_batch = sample_batch()"
      ],
      "metadata": {
        "id": "aGiytLc89R6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vizualizing out\n",
        "print(data_batch[500])\n",
        "print(label_batch[500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77ycTwe_BjZU",
        "outputId": "902a6f97-776a-4f6a-df63-259f11ef9dfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "tensor([7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recurrent Model"
      ],
      "metadata": {
        "id": "_L4qJ8LmB8ay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parameters and Hyperparameters"
      ],
      "metadata": {
        "id": "9pr-XM-YCFt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = {\n",
        "    'device':'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    'lr': 5e-5,\n",
        "    'weight_decay': 1e-7,\n",
        "    'num_epochs': 500\n",
        "}\n",
        "print(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klTf-7tNB3nS",
        "outputId": "a0ab2572-d9fb-43a5-bab5-8496e6a5c838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'device': 'cpu', 'lr': 5e-05, 'weight_decay': 1e-07, 'num_epochs': 500}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Recurrent NetWork\n",
        "\n",
        "class RNN(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, feature_size, out_size):\n",
        "\n",
        "        # inicializing __init__()\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        # Defining size parameters network\n",
        "        self.input_size = input_size\n",
        "        self.feature_size = feature_size\n",
        "        self.out_size = out_size\n",
        "\n",
        "        # Defining Layers\n",
        "        self.features = nn.GRU(self.input_size, self.feature_size, batch_first = True)\n",
        "        self.classifier = nn.Linear(self.feature_size, self.out_size)\n",
        "        self.softmax = nn.LogSoftmax(dim = -1)\n",
        "\n",
        "\n",
        "    def forward(self, X):\n",
        "\n",
        "        # Initialize the internal state of the RNN\n",
        "        batch_size = 1\n",
        "        features = torch.zeros(1, batch_size, self.feature_size).to(args['device'])\n",
        "\n",
        "        # Name.unsqueeze(0) - creating an artificial dimension for the batch = 1\n",
        "        X, features = self.features(X.unsqueeze(0), features)\n",
        "\n",
        "        X = self.classifier(X[:, -1])\n",
        "\n",
        "        X = self.softmax(X)\n",
        "        return X\n"
      ],
      "metadata": {
        "id": "mhGXRLACCdre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_size = 256\n",
        "\n",
        "net = RNN(size_dictionary, feature_size, len(categories))\n",
        "net.to(args['device'])"
      ],
      "metadata": {
        "id": "yK1lKLDiRjfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogd8og_cTkp1",
        "outputId": "87ba165a-fa39-4c24-c5eb-8c15deb2c56c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (features): GRU(52, 256, batch_first=True)\n",
              "  (classifier): Linear(in_features=256, out_features=18, bias=True)\n",
              "  (softmax): LogSoftmax(dim=-1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss"
      ],
      "metadata": {
        "id": "MV0a3rfsUi35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.NLLLoss().to(args['device'])"
      ],
      "metadata": {
        "id": "bEI9nxTHUXIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer"
      ],
      "metadata": {
        "id": "CF-wZGP9Uyhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(net.parameters(), lr = args['lr'], weight_decay = args['weight_decay'])"
      ],
      "metadata": {
        "id": "eUplEVLYUyBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Flow"
      ],
      "metadata": {
        "id": "uoNbUb9vVpF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function training and validation\n",
        "def forward(X, y, epoch, train = True):\n",
        "\n",
        "    # Defining\n",
        "    if train == True:\n",
        "        net.train()\n",
        "        mode = 'Training'\n",
        "    else:\n",
        "        net.eval()\n",
        "        mode = 'Validation'\n",
        "\n",
        "    # Accuracy and Loss epochs\n",
        "    accuracy = 0.\n",
        "    epochs_loss = []\n",
        "\n",
        "    for i, (data, label) in enumerate(zip(X, y)):\n",
        "\n",
        "        # Cast in device\n",
        "        data = data.to(args['device'])\n",
        "        label = label.to(args['device'])\n",
        "\n",
        "        # Prediction\n",
        "        y_pred = net(data)\n",
        "\n",
        "        # Loss calculate\n",
        "        loss = criterion(y_pred, label)\n",
        "\n",
        "        # List of Loss\n",
        "        epochs_loss.append(loss.detach().cpu().numpy())\n",
        "\n",
        "        # Exit from probabilities\n",
        "        _, pred = torch.max(y_pred, axis = -1)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy += 1 if pred[0].item() == label[0].item() else 0\n",
        "\n",
        "        # Optimization\n",
        "\n",
        "        if train == True:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Metrics from numpy\n",
        "    epochs_loss = np.asarray(epochs_loss).ravel()\n",
        "    accuracy = accuracy / float(len(epochs_loss))\n",
        "\n",
        "    # Inplace\n",
        "    print('\\n', '*' * 15, mode, '*' * 15)\n",
        "    print(f'Epoch: {epoch} Loss: {epochs_loss.mean():.2f} +/- {epochs_loss.std():.2f} -- Acc {accuracy:.2f}')\n",
        "\n",
        "    # Returning\n",
        "    return epochs_loss.mean(), accuracy"
      ],
      "metadata": {
        "id": "aeI_7353VN8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "UxSSpoyIZ0fH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, validation_loss = [], []\n",
        "train_accuracy, validation_accuracy = [], []"
      ],
      "metadata": {
        "id": "5WlT-j8dZyNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(args['num_epochs']):\n",
        "\n",
        "    # Training Batch\n",
        "    train_data, train_label = sample_batch()\n",
        "\n",
        "    # Validation Batch\n",
        "    validation_data, validation_label = sample_batch(size = 5)\n",
        "\n",
        "    # Training\n",
        "    loss, acc = forward(train_data, train_label, epoch = epoch, train = True)\n",
        "    train_loss.append(loss)\n",
        "    train_accuracy.append(acc)\n",
        "\n",
        "    # Validation\n",
        "    loss, acc = forward(validation_data, validation_label, epoch = epoch, train = False)\n",
        "    validation_loss.append(loss)\n",
        "    validation_accuracy.append(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meF4VjO8aJ--",
        "outputId": "81938c1e-0e87-4a8d-c14f-81e74f9094bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " *************** Training ***************\n",
            "Epoch: 0 Loss: 2.84 +/- 0.44 -- Acc 0.09\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 0 Loss: 2.98 +/- 0.69 -- Acc 0.06\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 1 Loss: 2.83 +/- 0.38 -- Acc 0.10\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 1 Loss: 2.89 +/- 0.84 -- Acc 0.11\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 2 Loss: 2.86 +/- 0.28 -- Acc 0.12\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 2 Loss: 2.89 +/- 0.61 -- Acc 0.11\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 3 Loss: 2.82 +/- 0.25 -- Acc 0.11\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 3 Loss: 2.87 +/- 0.55 -- Acc 0.11\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 4 Loss: 2.81 +/- 0.26 -- Acc 0.12\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 4 Loss: 2.78 +/- 0.26 -- Acc 0.12\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 5 Loss: 2.75 +/- 0.35 -- Acc 0.12\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 5 Loss: 2.77 +/- 0.18 -- Acc 0.21\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 6 Loss: 2.62 +/- 0.48 -- Acc 0.15\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 6 Loss: 2.77 +/- 0.23 -- Acc 0.12\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 7 Loss: 2.55 +/- 0.57 -- Acc 0.18\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 7 Loss: 2.91 +/- 0.50 -- Acc 0.09\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 8 Loss: 2.68 +/- 0.48 -- Acc 0.11\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 8 Loss: 2.80 +/- 0.49 -- Acc 0.17\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 9 Loss: 2.67 +/- 0.52 -- Acc 0.16\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 9 Loss: 2.73 +/- 0.49 -- Acc 0.15\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 10 Loss: 2.54 +/- 0.61 -- Acc 0.17\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 10 Loss: 2.71 +/- 0.53 -- Acc 0.19\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 11 Loss: 2.42 +/- 0.71 -- Acc 0.19\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 11 Loss: 2.81 +/- 0.65 -- Acc 0.17\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 12 Loss: 2.29 +/- 0.84 -- Acc 0.24\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 12 Loss: 2.74 +/- 0.57 -- Acc 0.12\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 13 Loss: 2.25 +/- 0.89 -- Acc 0.25\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 13 Loss: 3.04 +/- 0.82 -- Acc 0.08\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 14 Loss: 2.21 +/- 0.90 -- Acc 0.26\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 14 Loss: 3.07 +/- 0.96 -- Acc 0.10\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 15 Loss: 2.20 +/- 0.90 -- Acc 0.24\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 15 Loss: 3.26 +/- 1.14 -- Acc 0.10\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 16 Loss: 2.18 +/- 0.94 -- Acc 0.25\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 16 Loss: 3.51 +/- 1.33 -- Acc 0.10\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 17 Loss: 2.21 +/- 0.95 -- Acc 0.25\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 17 Loss: 3.31 +/- 1.51 -- Acc 0.16\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 18 Loss: 2.16 +/- 0.97 -- Acc 0.28\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 18 Loss: 3.47 +/- 1.62 -- Acc 0.11\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 19 Loss: 2.10 +/- 0.99 -- Acc 0.29\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 19 Loss: 3.37 +/- 1.58 -- Acc 0.13\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 20 Loss: 2.06 +/- 1.03 -- Acc 0.31\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 20 Loss: 3.24 +/- 1.40 -- Acc 0.08\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 21 Loss: 2.02 +/- 1.03 -- Acc 0.32\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 21 Loss: 3.03 +/- 1.23 -- Acc 0.10\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 22 Loss: 1.99 +/- 1.04 -- Acc 0.33\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 22 Loss: 2.98 +/- 1.26 -- Acc 0.11\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 23 Loss: 1.99 +/- 1.05 -- Acc 0.34\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 23 Loss: 3.14 +/- 1.42 -- Acc 0.11\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 24 Loss: 1.92 +/- 1.05 -- Acc 0.35\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 24 Loss: 3.28 +/- 1.48 -- Acc 0.12\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 25 Loss: 1.86 +/- 1.09 -- Acc 0.38\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 25 Loss: 3.28 +/- 1.46 -- Acc 0.09\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 26 Loss: 1.82 +/- 1.09 -- Acc 0.39\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 26 Loss: 3.71 +/- 1.86 -- Acc 0.12\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 27 Loss: 1.85 +/- 1.11 -- Acc 0.38\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 27 Loss: 3.62 +/- 1.83 -- Acc 0.12\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 28 Loss: 1.79 +/- 1.09 -- Acc 0.39\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 28 Loss: 3.69 +/- 1.89 -- Acc 0.12\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 29 Loss: 1.80 +/- 1.11 -- Acc 0.38\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 29 Loss: 3.74 +/- 1.89 -- Acc 0.16\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 30 Loss: 1.83 +/- 1.12 -- Acc 0.39\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 30 Loss: 3.46 +/- 1.82 -- Acc 0.16\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 31 Loss: 1.76 +/- 1.13 -- Acc 0.42\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 31 Loss: 3.55 +/- 1.71 -- Acc 0.14\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 32 Loss: 1.77 +/- 1.12 -- Acc 0.40\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 32 Loss: 3.66 +/- 1.88 -- Acc 0.10\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 33 Loss: 1.79 +/- 1.12 -- Acc 0.40\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 33 Loss: 3.67 +/- 1.83 -- Acc 0.11\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 34 Loss: 1.79 +/- 1.07 -- Acc 0.38\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 34 Loss: 3.64 +/- 1.98 -- Acc 0.08\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 35 Loss: 1.75 +/- 1.05 -- Acc 0.39\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 35 Loss: 3.82 +/- 2.09 -- Acc 0.14\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 36 Loss: 1.71 +/- 1.08 -- Acc 0.41\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 36 Loss: 3.90 +/- 2.05 -- Acc 0.07\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 37 Loss: 1.70 +/- 1.08 -- Acc 0.40\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 37 Loss: 3.73 +/- 1.78 -- Acc 0.10\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 38 Loss: 1.61 +/- 1.05 -- Acc 0.44\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 38 Loss: 3.56 +/- 1.76 -- Acc 0.13\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 39 Loss: 1.65 +/- 1.06 -- Acc 0.42\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 39 Loss: 3.86 +/- 2.00 -- Acc 0.10\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 40 Loss: 1.76 +/- 1.15 -- Acc 0.40\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 40 Loss: 4.08 +/- 1.97 -- Acc 0.07\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 41 Loss: 1.94 +/- 1.08 -- Acc 0.35\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 41 Loss: 3.61 +/- 1.81 -- Acc 0.14\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 42 Loss: 2.00 +/- 1.10 -- Acc 0.32\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 42 Loss: 3.94 +/- 2.04 -- Acc 0.10\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 43 Loss: 1.90 +/- 1.07 -- Acc 0.34\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 43 Loss: 3.83 +/- 2.02 -- Acc 0.11\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 44 Loss: 1.77 +/- 1.11 -- Acc 0.38\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 44 Loss: 3.89 +/- 2.30 -- Acc 0.11\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 45 Loss: 1.77 +/- 1.11 -- Acc 0.39\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 45 Loss: 3.81 +/- 2.17 -- Acc 0.15\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 46 Loss: 1.78 +/- 1.09 -- Acc 0.37\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 46 Loss: 3.68 +/- 2.26 -- Acc 0.16\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 47 Loss: 1.75 +/- 1.08 -- Acc 0.37\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 47 Loss: 3.73 +/- 1.98 -- Acc 0.07\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 48 Loss: 1.69 +/- 1.06 -- Acc 0.41\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 48 Loss: 3.61 +/- 2.22 -- Acc 0.16\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 49 Loss: 1.68 +/- 1.07 -- Acc 0.41\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 49 Loss: 3.51 +/- 1.97 -- Acc 0.15\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 50 Loss: 1.63 +/- 1.08 -- Acc 0.45\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 50 Loss: 3.51 +/- 2.08 -- Acc 0.13\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 51 Loss: 1.63 +/- 1.12 -- Acc 0.44\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 51 Loss: 4.09 +/- 2.31 -- Acc 0.12\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 52 Loss: 1.67 +/- 1.10 -- Acc 0.44\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 52 Loss: 3.58 +/- 2.18 -- Acc 0.13\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 53 Loss: 1.65 +/- 1.10 -- Acc 0.45\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 53 Loss: 3.87 +/- 2.26 -- Acc 0.16\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 54 Loss: 1.63 +/- 1.11 -- Acc 0.46\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 54 Loss: 4.20 +/- 2.50 -- Acc 0.19\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 55 Loss: 1.63 +/- 1.10 -- Acc 0.44\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 55 Loss: 4.09 +/- 2.45 -- Acc 0.12\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 56 Loss: 1.62 +/- 1.12 -- Acc 0.46\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 56 Loss: 3.73 +/- 2.26 -- Acc 0.14\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 57 Loss: 1.65 +/- 1.15 -- Acc 0.45\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 57 Loss: 3.71 +/- 2.11 -- Acc 0.09\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 58 Loss: 1.65 +/- 1.15 -- Acc 0.44\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 58 Loss: 3.53 +/- 1.90 -- Acc 0.15\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 59 Loss: 1.60 +/- 1.14 -- Acc 0.46\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 59 Loss: 3.28 +/- 1.85 -- Acc 0.18\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 60 Loss: 1.64 +/- 1.15 -- Acc 0.48\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 60 Loss: 3.46 +/- 1.78 -- Acc 0.09\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 61 Loss: 1.59 +/- 1.14 -- Acc 0.46\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 61 Loss: 3.38 +/- 2.07 -- Acc 0.20\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 62 Loss: 1.62 +/- 1.16 -- Acc 0.47\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 62 Loss: 3.31 +/- 1.94 -- Acc 0.17\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 63 Loss: 1.63 +/- 1.16 -- Acc 0.46\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 63 Loss: 3.88 +/- 2.43 -- Acc 0.16\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 64 Loss: 1.70 +/- 1.16 -- Acc 0.43\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 64 Loss: 3.14 +/- 1.84 -- Acc 0.17\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 65 Loss: 1.60 +/- 1.11 -- Acc 0.46\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 65 Loss: 3.78 +/- 2.12 -- Acc 0.13\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 66 Loss: 1.66 +/- 1.14 -- Acc 0.44\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 66 Loss: 3.67 +/- 2.29 -- Acc 0.20\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 67 Loss: 1.62 +/- 1.15 -- Acc 0.45\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 67 Loss: 3.60 +/- 2.22 -- Acc 0.16\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 68 Loss: 1.54 +/- 1.10 -- Acc 0.49\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 68 Loss: 3.78 +/- 2.09 -- Acc 0.10\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 69 Loss: 1.59 +/- 1.12 -- Acc 0.47\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 69 Loss: 3.52 +/- 1.98 -- Acc 0.13\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 70 Loss: 1.55 +/- 1.13 -- Acc 0.48\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 70 Loss: 3.13 +/- 1.92 -- Acc 0.18\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 71 Loss: 1.55 +/- 1.11 -- Acc 0.48\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 71 Loss: 3.63 +/- 2.21 -- Acc 0.19\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 72 Loss: 1.61 +/- 1.15 -- Acc 0.47\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 72 Loss: 3.15 +/- 1.93 -- Acc 0.26\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 73 Loss: 1.62 +/- 1.13 -- Acc 0.46\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 73 Loss: 3.33 +/- 2.08 -- Acc 0.20\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 74 Loss: 1.64 +/- 1.13 -- Acc 0.44\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 74 Loss: 3.05 +/- 1.82 -- Acc 0.17\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 75 Loss: 1.59 +/- 1.15 -- Acc 0.47\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 75 Loss: 3.16 +/- 1.94 -- Acc 0.27\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 76 Loss: 1.56 +/- 1.12 -- Acc 0.45\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 76 Loss: 2.99 +/- 1.86 -- Acc 0.21\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 77 Loss: 1.56 +/- 1.14 -- Acc 0.48\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 77 Loss: 2.90 +/- 1.62 -- Acc 0.20\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 78 Loss: 1.59 +/- 1.15 -- Acc 0.47\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 78 Loss: 3.36 +/- 1.97 -- Acc 0.16\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 79 Loss: 1.54 +/- 1.17 -- Acc 0.49\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 79 Loss: 3.17 +/- 1.71 -- Acc 0.18\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 80 Loss: 1.60 +/- 1.14 -- Acc 0.45\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 80 Loss: 3.36 +/- 1.98 -- Acc 0.18\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 81 Loss: 1.58 +/- 1.16 -- Acc 0.48\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 81 Loss: 3.76 +/- 2.18 -- Acc 0.17\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 82 Loss: 1.56 +/- 1.17 -- Acc 0.48\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 82 Loss: 3.56 +/- 2.22 -- Acc 0.12\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 83 Loss: 1.60 +/- 1.17 -- Acc 0.47\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 83 Loss: 3.15 +/- 2.00 -- Acc 0.16\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 84 Loss: 1.55 +/- 1.17 -- Acc 0.49\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 84 Loss: 3.20 +/- 2.06 -- Acc 0.19\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 85 Loss: 1.56 +/- 1.15 -- Acc 0.47\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 85 Loss: 3.48 +/- 2.29 -- Acc 0.22\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 86 Loss: 1.54 +/- 1.12 -- Acc 0.50\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 86 Loss: 3.30 +/- 2.08 -- Acc 0.21\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 87 Loss: 1.52 +/- 1.12 -- Acc 0.50\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 87 Loss: 3.04 +/- 1.94 -- Acc 0.24\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 88 Loss: 1.56 +/- 1.13 -- Acc 0.48\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 88 Loss: 3.17 +/- 1.85 -- Acc 0.14\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 89 Loss: 1.56 +/- 1.15 -- Acc 0.48\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 89 Loss: 3.11 +/- 1.92 -- Acc 0.21\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 90 Loss: 1.51 +/- 1.13 -- Acc 0.49\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 90 Loss: 3.24 +/- 1.92 -- Acc 0.25\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 91 Loss: 1.59 +/- 1.14 -- Acc 0.48\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 91 Loss: 3.12 +/- 1.85 -- Acc 0.19\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 92 Loss: 1.53 +/- 1.13 -- Acc 0.49\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 92 Loss: 3.49 +/- 1.96 -- Acc 0.16\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 93 Loss: 1.61 +/- 1.16 -- Acc 0.46\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 93 Loss: 3.34 +/- 1.98 -- Acc 0.18\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 94 Loss: 1.62 +/- 1.16 -- Acc 0.47\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 94 Loss: 3.02 +/- 1.59 -- Acc 0.16\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 95 Loss: 1.54 +/- 1.15 -- Acc 0.49\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 95 Loss: 3.19 +/- 2.05 -- Acc 0.25\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 96 Loss: 1.57 +/- 1.16 -- Acc 0.48\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 96 Loss: 3.27 +/- 2.02 -- Acc 0.20\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 97 Loss: 1.56 +/- 1.16 -- Acc 0.47\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 97 Loss: 3.30 +/- 2.03 -- Acc 0.18\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 98 Loss: 1.57 +/- 1.15 -- Acc 0.49\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 98 Loss: 3.34 +/- 2.08 -- Acc 0.20\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 99 Loss: 1.51 +/- 1.12 -- Acc 0.49\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 99 Loss: 3.13 +/- 1.81 -- Acc 0.23\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 100 Loss: 1.53 +/- 1.17 -- Acc 0.50\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 100 Loss: 3.17 +/- 2.00 -- Acc 0.19\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 101 Loss: 1.52 +/- 1.13 -- Acc 0.50\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 101 Loss: 3.02 +/- 1.77 -- Acc 0.18\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 102 Loss: 1.52 +/- 1.11 -- Acc 0.49\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 102 Loss: 3.06 +/- 1.93 -- Acc 0.24\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 103 Loss: 1.58 +/- 1.12 -- Acc 0.48\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 103 Loss: 3.17 +/- 1.83 -- Acc 0.18\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 104 Loss: 1.56 +/- 1.13 -- Acc 0.48\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 104 Loss: 2.99 +/- 2.01 -- Acc 0.23\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 105 Loss: 1.56 +/- 1.11 -- Acc 0.46\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 105 Loss: 3.08 +/- 1.85 -- Acc 0.18\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 106 Loss: 1.50 +/- 1.08 -- Acc 0.50\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 106 Loss: 3.03 +/- 1.84 -- Acc 0.26\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 107 Loss: 1.50 +/- 1.12 -- Acc 0.51\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 107 Loss: 2.92 +/- 1.89 -- Acc 0.24\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 108 Loss: 1.55 +/- 1.17 -- Acc 0.48\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 108 Loss: 3.34 +/- 2.07 -- Acc 0.11\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 109 Loss: 1.47 +/- 1.11 -- Acc 0.52\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 109 Loss: 3.28 +/- 2.11 -- Acc 0.19\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 110 Loss: 1.48 +/- 1.13 -- Acc 0.52\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 110 Loss: 3.36 +/- 2.23 -- Acc 0.19\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 111 Loss: 1.46 +/- 1.11 -- Acc 0.53\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 111 Loss: 3.05 +/- 2.10 -- Acc 0.26\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 112 Loss: 1.47 +/- 1.15 -- Acc 0.51\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 112 Loss: 3.22 +/- 2.20 -- Acc 0.20\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 113 Loss: 1.46 +/- 1.12 -- Acc 0.52\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 113 Loss: 3.40 +/- 2.20 -- Acc 0.19\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 114 Loss: 1.45 +/- 1.12 -- Acc 0.52\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 114 Loss: 3.03 +/- 1.88 -- Acc 0.18\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 115 Loss: 1.48 +/- 1.10 -- Acc 0.50\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 115 Loss: 2.76 +/- 2.12 -- Acc 0.28\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 116 Loss: 1.51 +/- 1.09 -- Acc 0.50\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 116 Loss: 3.05 +/- 2.01 -- Acc 0.24\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 117 Loss: 1.46 +/- 1.10 -- Acc 0.50\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 117 Loss: 2.82 +/- 1.88 -- Acc 0.25\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 118 Loss: 1.53 +/- 1.15 -- Acc 0.50\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 118 Loss: 2.67 +/- 1.65 -- Acc 0.25\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 119 Loss: 1.51 +/- 1.12 -- Acc 0.51\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 119 Loss: 2.85 +/- 1.85 -- Acc 0.18\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 120 Loss: 1.51 +/- 1.07 -- Acc 0.48\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 120 Loss: 2.78 +/- 1.77 -- Acc 0.22\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 121 Loss: 1.56 +/- 1.12 -- Acc 0.49\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 121 Loss: 3.09 +/- 2.21 -- Acc 0.32\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 122 Loss: 1.50 +/- 1.08 -- Acc 0.51\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 122 Loss: 3.05 +/- 2.09 -- Acc 0.26\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 123 Loss: 1.57 +/- 1.17 -- Acc 0.48\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 123 Loss: 2.52 +/- 1.77 -- Acc 0.36\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 124 Loss: 1.50 +/- 1.13 -- Acc 0.51\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 124 Loss: 2.43 +/- 1.62 -- Acc 0.29\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 125 Loss: 1.49 +/- 1.13 -- Acc 0.51\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 125 Loss: 2.82 +/- 1.80 -- Acc 0.28\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 126 Loss: 1.53 +/- 1.13 -- Acc 0.47\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 126 Loss: 2.88 +/- 2.01 -- Acc 0.28\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 127 Loss: 1.57 +/- 1.15 -- Acc 0.50\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 127 Loss: 2.49 +/- 1.63 -- Acc 0.30\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 128 Loss: 1.52 +/- 1.13 -- Acc 0.49\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 128 Loss: 2.83 +/- 2.04 -- Acc 0.31\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 129 Loss: 1.53 +/- 1.14 -- Acc 0.49\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 129 Loss: 2.77 +/- 1.78 -- Acc 0.24\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 130 Loss: 1.54 +/- 1.14 -- Acc 0.50\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 130 Loss: 2.63 +/- 1.61 -- Acc 0.26\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 131 Loss: 1.48 +/- 1.10 -- Acc 0.50\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 131 Loss: 2.61 +/- 1.68 -- Acc 0.27\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 132 Loss: 1.52 +/- 1.12 -- Acc 0.50\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 132 Loss: 2.84 +/- 2.02 -- Acc 0.27\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 133 Loss: 1.53 +/- 1.16 -- Acc 0.49\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 133 Loss: 2.79 +/- 1.87 -- Acc 0.27\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 134 Loss: 1.49 +/- 1.12 -- Acc 0.51\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 134 Loss: 2.44 +/- 1.47 -- Acc 0.26\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 135 Loss: 1.50 +/- 1.15 -- Acc 0.50\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 135 Loss: 2.52 +/- 1.83 -- Acc 0.36\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 136 Loss: 1.45 +/- 1.11 -- Acc 0.51\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 136 Loss: 2.84 +/- 1.81 -- Acc 0.26\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 137 Loss: 1.45 +/- 1.08 -- Acc 0.53\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 137 Loss: 2.57 +/- 1.73 -- Acc 0.29\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 138 Loss: 1.46 +/- 1.09 -- Acc 0.52\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 138 Loss: 2.48 +/- 1.41 -- Acc 0.27\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 139 Loss: 1.44 +/- 1.08 -- Acc 0.53\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 139 Loss: 2.04 +/- 1.26 -- Acc 0.35\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 140 Loss: 1.48 +/- 1.08 -- Acc 0.50\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 140 Loss: 2.53 +/- 1.70 -- Acc 0.28\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 141 Loss: 1.48 +/- 1.07 -- Acc 0.51\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 141 Loss: 2.32 +/- 1.53 -- Acc 0.35\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 142 Loss: 1.55 +/- 1.12 -- Acc 0.47\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 142 Loss: 2.42 +/- 1.77 -- Acc 0.31\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 143 Loss: 1.48 +/- 1.07 -- Acc 0.51\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 143 Loss: 2.42 +/- 1.60 -- Acc 0.35\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 144 Loss: 1.50 +/- 1.14 -- Acc 0.50\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 144 Loss: 2.24 +/- 1.45 -- Acc 0.34\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 145 Loss: 1.47 +/- 1.09 -- Acc 0.51\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 145 Loss: 2.65 +/- 1.98 -- Acc 0.26\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 146 Loss: 1.42 +/- 1.05 -- Acc 0.52\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 146 Loss: 2.56 +/- 1.96 -- Acc 0.30\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 147 Loss: 1.51 +/- 1.10 -- Acc 0.49\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 147 Loss: 2.23 +/- 1.67 -- Acc 0.42\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 148 Loss: 1.47 +/- 1.08 -- Acc 0.48\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 148 Loss: 2.67 +/- 1.87 -- Acc 0.30\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 149 Loss: 1.47 +/- 1.11 -- Acc 0.52\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 149 Loss: 2.04 +/- 1.53 -- Acc 0.39\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 150 Loss: 1.47 +/- 1.11 -- Acc 0.51\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 150 Loss: 2.40 +/- 1.82 -- Acc 0.38\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 151 Loss: 1.46 +/- 1.07 -- Acc 0.52\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 151 Loss: 2.46 +/- 1.67 -- Acc 0.30\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 152 Loss: 1.51 +/- 1.07 -- Acc 0.50\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 152 Loss: 2.25 +/- 1.63 -- Acc 0.35\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 153 Loss: 1.47 +/- 1.09 -- Acc 0.52\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 153 Loss: 2.27 +/- 1.57 -- Acc 0.36\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 154 Loss: 1.46 +/- 1.13 -- Acc 0.52\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 154 Loss: 2.26 +/- 1.65 -- Acc 0.31\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 155 Loss: 1.49 +/- 1.15 -- Acc 0.52\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 155 Loss: 2.18 +/- 1.57 -- Acc 0.34\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 156 Loss: 1.46 +/- 1.11 -- Acc 0.52\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 156 Loss: 2.24 +/- 1.56 -- Acc 0.34\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 157 Loss: 1.47 +/- 1.13 -- Acc 0.52\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 157 Loss: 2.10 +/- 1.50 -- Acc 0.30\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 158 Loss: 1.41 +/- 1.11 -- Acc 0.54\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 158 Loss: 2.28 +/- 1.73 -- Acc 0.38\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 159 Loss: 1.50 +/- 1.16 -- Acc 0.50\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 159 Loss: 1.93 +/- 1.49 -- Acc 0.42\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 160 Loss: 1.43 +/- 1.07 -- Acc 0.53\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 160 Loss: 2.04 +/- 1.69 -- Acc 0.47\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 161 Loss: 1.37 +/- 1.08 -- Acc 0.55\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 161 Loss: 2.31 +/- 1.69 -- Acc 0.36\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 162 Loss: 1.44 +/- 1.11 -- Acc 0.53\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 162 Loss: 1.95 +/- 1.43 -- Acc 0.43\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 163 Loss: 1.42 +/- 1.13 -- Acc 0.54\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 163 Loss: 1.96 +/- 1.33 -- Acc 0.40\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 164 Loss: 1.42 +/- 1.13 -- Acc 0.55\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 164 Loss: 2.09 +/- 1.34 -- Acc 0.31\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 165 Loss: 1.44 +/- 1.10 -- Acc 0.52\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 165 Loss: 2.20 +/- 1.62 -- Acc 0.38\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 166 Loss: 1.39 +/- 1.08 -- Acc 0.54\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 166 Loss: 2.08 +/- 1.58 -- Acc 0.39\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 167 Loss: 1.37 +/- 1.08 -- Acc 0.54\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 167 Loss: 2.00 +/- 1.68 -- Acc 0.47\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 168 Loss: 1.42 +/- 1.13 -- Acc 0.54\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 168 Loss: 1.89 +/- 1.18 -- Acc 0.32\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 169 Loss: 1.39 +/- 1.12 -- Acc 0.55\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 169 Loss: 2.06 +/- 1.68 -- Acc 0.37\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 170 Loss: 1.38 +/- 1.09 -- Acc 0.56\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 170 Loss: 2.15 +/- 1.36 -- Acc 0.31\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 171 Loss: 1.40 +/- 1.11 -- Acc 0.54\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 171 Loss: 1.92 +/- 1.36 -- Acc 0.39\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 172 Loss: 1.41 +/- 1.11 -- Acc 0.54\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 172 Loss: 1.91 +/- 1.53 -- Acc 0.45\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 173 Loss: 1.37 +/- 1.09 -- Acc 0.54\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 173 Loss: 1.95 +/- 1.57 -- Acc 0.45\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 174 Loss: 1.37 +/- 1.12 -- Acc 0.56\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 174 Loss: 1.97 +/- 1.71 -- Acc 0.37\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 175 Loss: 1.32 +/- 1.04 -- Acc 0.57\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 175 Loss: 1.73 +/- 1.53 -- Acc 0.50\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 176 Loss: 1.37 +/- 1.10 -- Acc 0.55\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 176 Loss: 1.92 +/- 1.37 -- Acc 0.39\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 177 Loss: 1.38 +/- 1.13 -- Acc 0.54\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 177 Loss: 1.85 +/- 1.54 -- Acc 0.49\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 178 Loss: 1.31 +/- 1.10 -- Acc 0.58\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 178 Loss: 2.11 +/- 1.58 -- Acc 0.40\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 179 Loss: 1.32 +/- 1.11 -- Acc 0.57\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 179 Loss: 1.98 +/- 1.54 -- Acc 0.42\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 180 Loss: 1.33 +/- 1.11 -- Acc 0.55\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 180 Loss: 1.78 +/- 1.38 -- Acc 0.40\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 181 Loss: 1.32 +/- 1.14 -- Acc 0.57\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 181 Loss: 1.90 +/- 1.46 -- Acc 0.40\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 182 Loss: 1.30 +/- 1.07 -- Acc 0.58\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 182 Loss: 1.67 +/- 1.14 -- Acc 0.38\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 183 Loss: 1.30 +/- 1.10 -- Acc 0.57\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 183 Loss: 1.91 +/- 1.49 -- Acc 0.43\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 184 Loss: 1.29 +/- 1.12 -- Acc 0.58\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 184 Loss: 1.78 +/- 1.16 -- Acc 0.43\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 185 Loss: 1.27 +/- 1.10 -- Acc 0.60\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 185 Loss: 1.94 +/- 1.64 -- Acc 0.43\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 186 Loss: 1.35 +/- 1.12 -- Acc 0.56\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 186 Loss: 1.83 +/- 1.47 -- Acc 0.43\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 187 Loss: 1.32 +/- 1.11 -- Acc 0.59\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 187 Loss: 2.05 +/- 1.67 -- Acc 0.40\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 188 Loss: 1.31 +/- 1.19 -- Acc 0.60\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 188 Loss: 1.85 +/- 1.31 -- Acc 0.40\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 189 Loss: 1.26 +/- 1.10 -- Acc 0.60\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 189 Loss: 1.69 +/- 1.30 -- Acc 0.47\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 190 Loss: 1.26 +/- 1.08 -- Acc 0.59\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 190 Loss: 2.12 +/- 1.67 -- Acc 0.34\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 191 Loss: 1.32 +/- 1.16 -- Acc 0.59\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 191 Loss: 1.83 +/- 1.44 -- Acc 0.48\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 192 Loss: 1.27 +/- 1.08 -- Acc 0.60\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 192 Loss: 1.78 +/- 1.29 -- Acc 0.42\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 193 Loss: 1.24 +/- 1.10 -- Acc 0.59\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 193 Loss: 1.72 +/- 1.43 -- Acc 0.47\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 194 Loss: 1.28 +/- 1.08 -- Acc 0.59\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 194 Loss: 1.67 +/- 1.35 -- Acc 0.47\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 195 Loss: 1.25 +/- 1.13 -- Acc 0.60\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 195 Loss: 1.61 +/- 1.32 -- Acc 0.51\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 196 Loss: 1.22 +/- 1.08 -- Acc 0.62\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 196 Loss: 1.67 +/- 1.42 -- Acc 0.47\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 197 Loss: 1.26 +/- 1.10 -- Acc 0.59\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 197 Loss: 1.54 +/- 1.41 -- Acc 0.52\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 198 Loss: 1.24 +/- 1.07 -- Acc 0.59\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 198 Loss: 1.70 +/- 1.34 -- Acc 0.48\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 199 Loss: 1.25 +/- 1.12 -- Acc 0.59\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 199 Loss: 1.96 +/- 1.57 -- Acc 0.37\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 200 Loss: 1.24 +/- 1.10 -- Acc 0.59\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 200 Loss: 1.63 +/- 1.39 -- Acc 0.47\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 201 Loss: 1.25 +/- 1.09 -- Acc 0.59\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 201 Loss: 1.53 +/- 1.42 -- Acc 0.57\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 202 Loss: 1.19 +/- 1.09 -- Acc 0.62\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 202 Loss: 1.61 +/- 1.25 -- Acc 0.48\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 203 Loss: 1.18 +/- 1.06 -- Acc 0.61\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 203 Loss: 1.85 +/- 1.63 -- Acc 0.47\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 204 Loss: 1.17 +/- 1.02 -- Acc 0.62\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 204 Loss: 1.43 +/- 1.27 -- Acc 0.55\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 205 Loss: 1.20 +/- 1.14 -- Acc 0.62\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 205 Loss: 1.55 +/- 1.36 -- Acc 0.49\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 206 Loss: 1.22 +/- 1.10 -- Acc 0.60\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 206 Loss: 1.49 +/- 1.24 -- Acc 0.52\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 207 Loss: 1.16 +/- 1.06 -- Acc 0.62\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 207 Loss: 1.32 +/- 1.13 -- Acc 0.54\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 208 Loss: 1.21 +/- 1.11 -- Acc 0.61\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 208 Loss: 1.62 +/- 1.30 -- Acc 0.47\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 209 Loss: 1.22 +/- 1.11 -- Acc 0.63\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 209 Loss: 1.37 +/- 1.20 -- Acc 0.56\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 210 Loss: 1.15 +/- 1.06 -- Acc 0.63\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 210 Loss: 1.25 +/- 1.00 -- Acc 0.56\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 211 Loss: 1.22 +/- 1.10 -- Acc 0.60\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 211 Loss: 1.49 +/- 1.23 -- Acc 0.52\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 212 Loss: 1.19 +/- 1.07 -- Acc 0.61\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 212 Loss: 1.20 +/- 0.96 -- Acc 0.52\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 213 Loss: 1.17 +/- 1.05 -- Acc 0.62\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 213 Loss: 1.33 +/- 1.11 -- Acc 0.56\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 214 Loss: 1.16 +/- 1.12 -- Acc 0.63\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 214 Loss: 1.38 +/- 1.17 -- Acc 0.52\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 215 Loss: 1.17 +/- 1.06 -- Acc 0.63\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 215 Loss: 1.30 +/- 1.21 -- Acc 0.61\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 216 Loss: 1.16 +/- 1.11 -- Acc 0.64\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 216 Loss: 1.33 +/- 1.16 -- Acc 0.58\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 217 Loss: 1.15 +/- 1.07 -- Acc 0.62\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 217 Loss: 1.10 +/- 0.96 -- Acc 0.58\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 218 Loss: 1.14 +/- 1.06 -- Acc 0.64\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 218 Loss: 1.51 +/- 1.46 -- Acc 0.59\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 219 Loss: 1.15 +/- 1.07 -- Acc 0.63\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 219 Loss: 1.39 +/- 1.19 -- Acc 0.50\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 220 Loss: 1.14 +/- 1.07 -- Acc 0.64\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 220 Loss: 1.36 +/- 1.16 -- Acc 0.56\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 221 Loss: 1.12 +/- 1.09 -- Acc 0.64\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 221 Loss: 1.31 +/- 1.30 -- Acc 0.64\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 222 Loss: 1.17 +/- 1.12 -- Acc 0.63\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 222 Loss: 1.36 +/- 1.16 -- Acc 0.49\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 223 Loss: 1.10 +/- 1.08 -- Acc 0.64\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 223 Loss: 1.36 +/- 0.98 -- Acc 0.55\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 224 Loss: 1.11 +/- 1.09 -- Acc 0.65\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 224 Loss: 1.19 +/- 0.96 -- Acc 0.60\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 225 Loss: 1.09 +/- 1.07 -- Acc 0.66\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 225 Loss: 1.07 +/- 1.00 -- Acc 0.66\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 226 Loss: 1.06 +/- 1.05 -- Acc 0.67\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 226 Loss: 1.30 +/- 1.13 -- Acc 0.57\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 227 Loss: 1.12 +/- 1.07 -- Acc 0.63\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 227 Loss: 1.19 +/- 1.05 -- Acc 0.64\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 228 Loss: 1.10 +/- 1.09 -- Acc 0.65\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 228 Loss: 1.14 +/- 1.14 -- Acc 0.69\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 229 Loss: 1.08 +/- 1.07 -- Acc 0.66\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 229 Loss: 1.50 +/- 1.12 -- Acc 0.47\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 230 Loss: 1.06 +/- 1.04 -- Acc 0.66\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 230 Loss: 1.17 +/- 1.13 -- Acc 0.62\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 231 Loss: 1.05 +/- 1.02 -- Acc 0.67\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 231 Loss: 1.25 +/- 1.09 -- Acc 0.56\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 232 Loss: 1.09 +/- 1.07 -- Acc 0.64\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 232 Loss: 1.30 +/- 1.42 -- Acc 0.62\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 233 Loss: 1.02 +/- 1.03 -- Acc 0.66\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 233 Loss: 1.30 +/- 1.20 -- Acc 0.52\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 234 Loss: 1.06 +/- 1.05 -- Acc 0.66\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 234 Loss: 1.15 +/- 1.02 -- Acc 0.65\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 235 Loss: 1.08 +/- 1.06 -- Acc 0.64\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 235 Loss: 1.23 +/- 1.28 -- Acc 0.68\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 236 Loss: 1.07 +/- 1.08 -- Acc 0.66\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 236 Loss: 1.36 +/- 1.35 -- Acc 0.61\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 237 Loss: 1.02 +/- 1.04 -- Acc 0.67\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 237 Loss: 1.12 +/- 1.04 -- Acc 0.63\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 238 Loss: 1.04 +/- 1.00 -- Acc 0.66\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 238 Loss: 1.42 +/- 1.40 -- Acc 0.56\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 239 Loss: 1.07 +/- 1.07 -- Acc 0.66\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 239 Loss: 1.32 +/- 1.13 -- Acc 0.59\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 240 Loss: 1.07 +/- 1.09 -- Acc 0.68\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 240 Loss: 1.30 +/- 1.15 -- Acc 0.60\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 241 Loss: 1.01 +/- 1.01 -- Acc 0.68\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 241 Loss: 1.42 +/- 1.30 -- Acc 0.49\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 242 Loss: 1.00 +/- 1.00 -- Acc 0.68\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 242 Loss: 1.21 +/- 1.24 -- Acc 0.61\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 243 Loss: 1.02 +/- 1.01 -- Acc 0.67\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 243 Loss: 1.06 +/- 1.13 -- Acc 0.71\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 244 Loss: 0.99 +/- 1.04 -- Acc 0.70\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 244 Loss: 1.22 +/- 1.31 -- Acc 0.60\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 245 Loss: 1.01 +/- 1.04 -- Acc 0.69\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 245 Loss: 1.31 +/- 1.21 -- Acc 0.54\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 246 Loss: 1.00 +/- 1.01 -- Acc 0.68\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 246 Loss: 0.99 +/- 0.97 -- Acc 0.68\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 247 Loss: 1.03 +/- 1.05 -- Acc 0.67\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 247 Loss: 1.09 +/- 0.99 -- Acc 0.64\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 248 Loss: 1.00 +/- 1.00 -- Acc 0.69\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 248 Loss: 1.17 +/- 1.00 -- Acc 0.59\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 249 Loss: 1.07 +/- 1.11 -- Acc 0.67\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 249 Loss: 1.20 +/- 1.12 -- Acc 0.62\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 250 Loss: 1.01 +/- 1.02 -- Acc 0.68\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 250 Loss: 1.26 +/- 1.19 -- Acc 0.56\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 251 Loss: 1.02 +/- 1.05 -- Acc 0.69\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 251 Loss: 1.16 +/- 1.09 -- Acc 0.60\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 252 Loss: 0.95 +/- 0.99 -- Acc 0.72\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 252 Loss: 1.15 +/- 1.13 -- Acc 0.59\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 253 Loss: 0.96 +/- 0.99 -- Acc 0.70\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 253 Loss: 0.97 +/- 0.89 -- Acc 0.66\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 254 Loss: 0.94 +/- 0.96 -- Acc 0.69\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 254 Loss: 1.07 +/- 1.17 -- Acc 0.68\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 255 Loss: 0.98 +/- 1.06 -- Acc 0.70\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 255 Loss: 1.13 +/- 1.26 -- Acc 0.64\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 256 Loss: 0.97 +/- 1.05 -- Acc 0.71\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 256 Loss: 1.03 +/- 0.93 -- Acc 0.67\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 257 Loss: 0.91 +/- 1.00 -- Acc 0.72\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 257 Loss: 1.14 +/- 1.22 -- Acc 0.64\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 258 Loss: 0.91 +/- 1.00 -- Acc 0.72\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 258 Loss: 1.12 +/- 1.10 -- Acc 0.61\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 259 Loss: 0.96 +/- 1.03 -- Acc 0.70\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 259 Loss: 1.11 +/- 1.35 -- Acc 0.69\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 260 Loss: 0.97 +/- 1.12 -- Acc 0.70\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 260 Loss: 1.22 +/- 1.20 -- Acc 0.60\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 261 Loss: 0.96 +/- 1.02 -- Acc 0.71\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 261 Loss: 0.86 +/- 0.79 -- Acc 0.71\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 262 Loss: 0.97 +/- 1.04 -- Acc 0.70\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 262 Loss: 0.83 +/- 0.79 -- Acc 0.77\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 263 Loss: 0.92 +/- 1.00 -- Acc 0.71\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 263 Loss: 0.92 +/- 1.03 -- Acc 0.76\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 264 Loss: 0.91 +/- 1.02 -- Acc 0.72\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 264 Loss: 1.07 +/- 0.94 -- Acc 0.60\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 265 Loss: 0.92 +/- 1.07 -- Acc 0.72\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 265 Loss: 1.05 +/- 1.09 -- Acc 0.63\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 266 Loss: 0.87 +/- 0.94 -- Acc 0.72\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 266 Loss: 0.99 +/- 0.90 -- Acc 0.69\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 267 Loss: 0.92 +/- 1.01 -- Acc 0.70\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 267 Loss: 1.04 +/- 1.06 -- Acc 0.66\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 268 Loss: 0.85 +/- 1.00 -- Acc 0.75\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 268 Loss: 0.92 +/- 1.03 -- Acc 0.74\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 269 Loss: 0.94 +/- 1.09 -- Acc 0.72\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 269 Loss: 0.95 +/- 1.02 -- Acc 0.70\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 270 Loss: 0.89 +/- 1.04 -- Acc 0.72\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 270 Loss: 1.00 +/- 0.98 -- Acc 0.66\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 271 Loss: 0.97 +/- 1.12 -- Acc 0.70\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 271 Loss: 0.84 +/- 0.90 -- Acc 0.69\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 272 Loss: 0.86 +/- 0.99 -- Acc 0.74\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 272 Loss: 0.91 +/- 1.01 -- Acc 0.74\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 273 Loss: 0.86 +/- 0.97 -- Acc 0.73\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 273 Loss: 0.97 +/- 1.12 -- Acc 0.68\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 274 Loss: 0.88 +/- 1.02 -- Acc 0.73\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 274 Loss: 1.13 +/- 1.20 -- Acc 0.61\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 275 Loss: 0.88 +/- 0.99 -- Acc 0.73\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 275 Loss: 1.03 +/- 1.05 -- Acc 0.66\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 276 Loss: 0.85 +/- 0.95 -- Acc 0.73\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 276 Loss: 1.00 +/- 1.14 -- Acc 0.65\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 277 Loss: 0.85 +/- 0.98 -- Acc 0.74\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 277 Loss: 1.01 +/- 0.96 -- Acc 0.65\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 278 Loss: 0.86 +/- 0.96 -- Acc 0.72\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 278 Loss: 0.87 +/- 1.01 -- Acc 0.72\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 279 Loss: 0.83 +/- 1.01 -- Acc 0.75\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 279 Loss: 0.75 +/- 0.81 -- Acc 0.78\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 280 Loss: 0.86 +/- 0.97 -- Acc 0.73\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 280 Loss: 0.85 +/- 0.97 -- Acc 0.75\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 281 Loss: 0.83 +/- 0.98 -- Acc 0.75\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 281 Loss: 0.94 +/- 0.96 -- Acc 0.69\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 282 Loss: 0.78 +/- 0.94 -- Acc 0.77\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 282 Loss: 0.88 +/- 1.15 -- Acc 0.76\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 283 Loss: 0.81 +/- 0.95 -- Acc 0.75\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 283 Loss: 0.94 +/- 1.04 -- Acc 0.69\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 284 Loss: 0.85 +/- 1.07 -- Acc 0.75\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 284 Loss: 0.79 +/- 0.87 -- Acc 0.71\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 285 Loss: 0.81 +/- 0.96 -- Acc 0.76\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 285 Loss: 0.83 +/- 0.89 -- Acc 0.79\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 286 Loss: 0.82 +/- 0.94 -- Acc 0.76\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 286 Loss: 0.83 +/- 1.01 -- Acc 0.74\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 287 Loss: 0.79 +/- 0.94 -- Acc 0.76\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 287 Loss: 0.77 +/- 0.82 -- Acc 0.75\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 288 Loss: 0.82 +/- 0.95 -- Acc 0.74\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 288 Loss: 0.97 +/- 1.16 -- Acc 0.68\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 289 Loss: 0.80 +/- 0.98 -- Acc 0.75\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 289 Loss: 0.90 +/- 0.81 -- Acc 0.69\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 290 Loss: 0.80 +/- 0.95 -- Acc 0.76\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 290 Loss: 0.84 +/- 0.93 -- Acc 0.73\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 291 Loss: 0.77 +/- 0.94 -- Acc 0.77\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 291 Loss: 1.05 +/- 1.21 -- Acc 0.68\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 292 Loss: 0.77 +/- 0.98 -- Acc 0.77\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 292 Loss: 0.83 +/- 1.14 -- Acc 0.78\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 293 Loss: 0.81 +/- 1.02 -- Acc 0.75\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 293 Loss: 0.81 +/- 1.00 -- Acc 0.74\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 294 Loss: 0.80 +/- 1.00 -- Acc 0.76\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 294 Loss: 0.78 +/- 0.92 -- Acc 0.74\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 295 Loss: 0.80 +/- 0.96 -- Acc 0.76\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 295 Loss: 0.73 +/- 0.94 -- Acc 0.74\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 296 Loss: 0.74 +/- 0.91 -- Acc 0.77\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 296 Loss: 0.72 +/- 0.97 -- Acc 0.75\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 297 Loss: 0.79 +/- 1.00 -- Acc 0.76\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 297 Loss: 0.81 +/- 1.13 -- Acc 0.81\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 298 Loss: 0.76 +/- 0.97 -- Acc 0.77\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 298 Loss: 0.66 +/- 0.75 -- Acc 0.75\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 299 Loss: 0.79 +/- 0.99 -- Acc 0.76\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 299 Loss: 0.84 +/- 0.97 -- Acc 0.74\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 300 Loss: 0.78 +/- 0.96 -- Acc 0.77\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 300 Loss: 0.64 +/- 0.90 -- Acc 0.79\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 301 Loss: 0.74 +/- 0.89 -- Acc 0.77\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 301 Loss: 0.73 +/- 0.91 -- Acc 0.79\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 302 Loss: 0.76 +/- 0.90 -- Acc 0.75\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 302 Loss: 0.71 +/- 0.80 -- Acc 0.76\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 303 Loss: 0.77 +/- 0.97 -- Acc 0.77\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 303 Loss: 0.65 +/- 0.86 -- Acc 0.77\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 304 Loss: 0.72 +/- 0.88 -- Acc 0.77\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 304 Loss: 0.68 +/- 0.76 -- Acc 0.79\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 305 Loss: 0.72 +/- 0.90 -- Acc 0.78\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 305 Loss: 0.81 +/- 1.05 -- Acc 0.73\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 306 Loss: 0.75 +/- 0.92 -- Acc 0.78\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 306 Loss: 0.77 +/- 1.04 -- Acc 0.72\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 307 Loss: 0.73 +/- 0.89 -- Acc 0.77\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 307 Loss: 0.65 +/- 0.81 -- Acc 0.83\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 308 Loss: 0.73 +/- 0.91 -- Acc 0.77\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 308 Loss: 0.95 +/- 1.21 -- Acc 0.72\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 309 Loss: 0.72 +/- 0.91 -- Acc 0.78\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 309 Loss: 0.81 +/- 0.88 -- Acc 0.69\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 310 Loss: 0.71 +/- 0.93 -- Acc 0.79\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 310 Loss: 0.69 +/- 0.87 -- Acc 0.76\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 311 Loss: 0.76 +/- 0.96 -- Acc 0.76\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 311 Loss: 0.63 +/- 0.85 -- Acc 0.81\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 312 Loss: 0.69 +/- 0.90 -- Acc 0.78\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 312 Loss: 0.70 +/- 0.75 -- Acc 0.73\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 313 Loss: 0.70 +/- 0.89 -- Acc 0.79\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 313 Loss: 0.70 +/- 0.82 -- Acc 0.81\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 314 Loss: 0.69 +/- 0.90 -- Acc 0.79\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 314 Loss: 0.79 +/- 1.05 -- Acc 0.78\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 315 Loss: 0.68 +/- 0.88 -- Acc 0.79\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 315 Loss: 0.67 +/- 0.88 -- Acc 0.81\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 316 Loss: 0.71 +/- 0.96 -- Acc 0.79\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 316 Loss: 0.65 +/- 0.93 -- Acc 0.81\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 317 Loss: 0.70 +/- 0.93 -- Acc 0.79\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 317 Loss: 0.57 +/- 0.79 -- Acc 0.83\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 318 Loss: 0.69 +/- 0.86 -- Acc 0.79\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 318 Loss: 0.66 +/- 1.19 -- Acc 0.83\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 319 Loss: 0.64 +/- 0.86 -- Acc 0.81\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 319 Loss: 0.80 +/- 0.98 -- Acc 0.68\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 320 Loss: 0.71 +/- 0.96 -- Acc 0.79\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 320 Loss: 0.80 +/- 1.00 -- Acc 0.73\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 321 Loss: 0.70 +/- 0.91 -- Acc 0.79\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 321 Loss: 0.65 +/- 0.83 -- Acc 0.80\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 322 Loss: 0.66 +/- 0.90 -- Acc 0.81\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 322 Loss: 0.79 +/- 1.00 -- Acc 0.75\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 323 Loss: 0.69 +/- 0.94 -- Acc 0.79\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 323 Loss: 0.61 +/- 0.72 -- Acc 0.83\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 324 Loss: 0.71 +/- 0.93 -- Acc 0.78\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 324 Loss: 0.64 +/- 0.84 -- Acc 0.81\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 325 Loss: 0.71 +/- 0.96 -- Acc 0.78\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 325 Loss: 0.64 +/- 0.81 -- Acc 0.81\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 326 Loss: 0.63 +/- 0.84 -- Acc 0.81\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 326 Loss: 0.57 +/- 0.68 -- Acc 0.83\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 327 Loss: 0.65 +/- 0.88 -- Acc 0.80\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 327 Loss: 0.68 +/- 0.86 -- Acc 0.75\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 328 Loss: 0.66 +/- 0.96 -- Acc 0.81\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 328 Loss: 0.62 +/- 0.79 -- Acc 0.84\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 329 Loss: 0.63 +/- 0.84 -- Acc 0.81\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 329 Loss: 0.63 +/- 0.97 -- Acc 0.83\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 330 Loss: 0.66 +/- 0.90 -- Acc 0.79\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 330 Loss: 0.68 +/- 1.11 -- Acc 0.81\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 331 Loss: 0.68 +/- 0.94 -- Acc 0.80\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 331 Loss: 0.64 +/- 1.17 -- Acc 0.84\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 332 Loss: 0.61 +/- 0.84 -- Acc 0.80\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 332 Loss: 0.93 +/- 1.36 -- Acc 0.72\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 333 Loss: 0.62 +/- 0.89 -- Acc 0.82\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 333 Loss: 0.66 +/- 1.02 -- Acc 0.83\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 334 Loss: 0.67 +/- 0.96 -- Acc 0.80\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 334 Loss: 0.70 +/- 0.93 -- Acc 0.76\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 335 Loss: 0.63 +/- 0.91 -- Acc 0.82\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 335 Loss: 0.69 +/- 0.93 -- Acc 0.78\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 336 Loss: 0.67 +/- 0.96 -- Acc 0.80\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 336 Loss: 0.61 +/- 0.73 -- Acc 0.77\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 337 Loss: 0.65 +/- 0.97 -- Acc 0.81\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 337 Loss: 0.61 +/- 0.81 -- Acc 0.79\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 338 Loss: 0.64 +/- 0.96 -- Acc 0.81\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 338 Loss: 0.67 +/- 0.83 -- Acc 0.79\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 339 Loss: 0.66 +/- 0.95 -- Acc 0.81\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 339 Loss: 0.71 +/- 0.85 -- Acc 0.77\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 340 Loss: 0.63 +/- 0.83 -- Acc 0.80\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 340 Loss: 0.68 +/- 0.92 -- Acc 0.77\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 341 Loss: 0.65 +/- 0.88 -- Acc 0.79\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 341 Loss: 0.59 +/- 0.77 -- Acc 0.79\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 342 Loss: 0.62 +/- 0.90 -- Acc 0.83\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 342 Loss: 0.61 +/- 0.76 -- Acc 0.79\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 343 Loss: 0.60 +/- 0.89 -- Acc 0.81\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 343 Loss: 0.61 +/- 0.95 -- Acc 0.82\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 344 Loss: 0.64 +/- 0.90 -- Acc 0.80\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 344 Loss: 0.48 +/- 0.73 -- Acc 0.85\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 345 Loss: 0.63 +/- 0.87 -- Acc 0.80\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 345 Loss: 0.51 +/- 0.76 -- Acc 0.89\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 346 Loss: 0.62 +/- 0.88 -- Acc 0.82\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 346 Loss: 0.63 +/- 0.86 -- Acc 0.82\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 347 Loss: 0.60 +/- 0.85 -- Acc 0.82\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 347 Loss: 0.59 +/- 0.91 -- Acc 0.82\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 348 Loss: 0.59 +/- 0.79 -- Acc 0.82\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 348 Loss: 0.65 +/- 0.89 -- Acc 0.77\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 349 Loss: 0.58 +/- 0.84 -- Acc 0.83\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 349 Loss: 0.60 +/- 0.83 -- Acc 0.84\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 350 Loss: 0.57 +/- 0.87 -- Acc 0.82\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 350 Loss: 0.52 +/- 0.62 -- Acc 0.87\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 351 Loss: 0.58 +/- 0.81 -- Acc 0.82\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 351 Loss: 0.70 +/- 1.05 -- Acc 0.82\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 352 Loss: 0.59 +/- 0.85 -- Acc 0.81\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 352 Loss: 0.57 +/- 0.79 -- Acc 0.81\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 353 Loss: 0.61 +/- 0.94 -- Acc 0.82\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 353 Loss: 0.53 +/- 0.81 -- Acc 0.87\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 354 Loss: 0.56 +/- 0.85 -- Acc 0.84\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 354 Loss: 0.52 +/- 0.77 -- Acc 0.85\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 355 Loss: 0.60 +/- 0.90 -- Acc 0.81\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 355 Loss: 0.44 +/- 0.57 -- Acc 0.88\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 356 Loss: 0.54 +/- 0.78 -- Acc 0.82\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 356 Loss: 0.61 +/- 0.88 -- Acc 0.77\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 357 Loss: 0.58 +/- 0.91 -- Acc 0.83\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 357 Loss: 0.48 +/- 0.68 -- Acc 0.87\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 358 Loss: 0.53 +/- 0.79 -- Acc 0.84\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 358 Loss: 0.54 +/- 0.79 -- Acc 0.87\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 359 Loss: 0.56 +/- 0.87 -- Acc 0.84\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 359 Loss: 0.60 +/- 0.82 -- Acc 0.80\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 360 Loss: 0.54 +/- 0.82 -- Acc 0.84\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 360 Loss: 0.64 +/- 0.90 -- Acc 0.78\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 361 Loss: 0.62 +/- 0.91 -- Acc 0.81\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 361 Loss: 0.59 +/- 0.87 -- Acc 0.83\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 362 Loss: 0.55 +/- 0.81 -- Acc 0.84\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 362 Loss: 0.49 +/- 0.68 -- Acc 0.87\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 363 Loss: 0.60 +/- 0.92 -- Acc 0.82\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 363 Loss: 0.65 +/- 0.88 -- Acc 0.81\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 364 Loss: 0.57 +/- 0.90 -- Acc 0.83\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 364 Loss: 0.35 +/- 0.48 -- Acc 0.89\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 365 Loss: 0.55 +/- 0.87 -- Acc 0.83\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 365 Loss: 0.53 +/- 0.71 -- Acc 0.83\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 366 Loss: 0.53 +/- 0.87 -- Acc 0.83\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 366 Loss: 0.43 +/- 0.60 -- Acc 0.85\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 367 Loss: 0.53 +/- 0.78 -- Acc 0.84\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 367 Loss: 0.49 +/- 0.69 -- Acc 0.85\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 368 Loss: 0.53 +/- 0.82 -- Acc 0.84\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 368 Loss: 0.50 +/- 0.75 -- Acc 0.89\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 369 Loss: 0.51 +/- 0.83 -- Acc 0.85\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 369 Loss: 0.58 +/- 0.90 -- Acc 0.85\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 370 Loss: 0.51 +/- 0.79 -- Acc 0.85\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 370 Loss: 0.49 +/- 0.91 -- Acc 0.88\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 371 Loss: 0.55 +/- 0.88 -- Acc 0.84\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 371 Loss: 0.51 +/- 0.73 -- Acc 0.85\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 372 Loss: 0.57 +/- 0.91 -- Acc 0.83\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 372 Loss: 0.41 +/- 0.61 -- Acc 0.88\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 373 Loss: 0.55 +/- 0.83 -- Acc 0.83\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 373 Loss: 0.50 +/- 0.96 -- Acc 0.85\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 374 Loss: 0.49 +/- 0.75 -- Acc 0.86\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 374 Loss: 0.54 +/- 1.07 -- Acc 0.88\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 375 Loss: 0.53 +/- 0.85 -- Acc 0.84\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 375 Loss: 0.54 +/- 0.72 -- Acc 0.80\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 376 Loss: 0.56 +/- 0.93 -- Acc 0.84\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 376 Loss: 0.46 +/- 0.64 -- Acc 0.87\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 377 Loss: 0.50 +/- 0.84 -- Acc 0.86\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 377 Loss: 0.38 +/- 0.66 -- Acc 0.91\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 378 Loss: 0.53 +/- 0.84 -- Acc 0.83\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 378 Loss: 0.37 +/- 0.54 -- Acc 0.91\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 379 Loss: 0.51 +/- 0.80 -- Acc 0.84\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 379 Loss: 0.55 +/- 0.79 -- Acc 0.84\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 380 Loss: 0.46 +/- 0.71 -- Acc 0.86\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 380 Loss: 0.68 +/- 1.12 -- Acc 0.76\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 381 Loss: 0.56 +/- 0.88 -- Acc 0.83\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 381 Loss: 0.45 +/- 0.76 -- Acc 0.88\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 382 Loss: 0.55 +/- 0.91 -- Acc 0.84\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 382 Loss: 0.64 +/- 1.11 -- Acc 0.83\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 383 Loss: 0.48 +/- 0.75 -- Acc 0.86\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 383 Loss: 0.48 +/- 0.73 -- Acc 0.82\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 384 Loss: 0.54 +/- 0.88 -- Acc 0.84\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 384 Loss: 0.41 +/- 0.61 -- Acc 0.91\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 385 Loss: 0.49 +/- 0.81 -- Acc 0.86\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 385 Loss: 0.46 +/- 0.74 -- Acc 0.86\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 386 Loss: 0.49 +/- 0.88 -- Acc 0.86\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 386 Loss: 0.47 +/- 0.86 -- Acc 0.91\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 387 Loss: 0.52 +/- 0.87 -- Acc 0.84\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 387 Loss: 0.38 +/- 0.51 -- Acc 0.90\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 388 Loss: 0.50 +/- 0.81 -- Acc 0.85\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 388 Loss: 0.48 +/- 0.82 -- Acc 0.86\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 389 Loss: 0.50 +/- 0.81 -- Acc 0.85\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 389 Loss: 0.49 +/- 0.71 -- Acc 0.82\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 390 Loss: 0.50 +/- 0.79 -- Acc 0.84\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 390 Loss: 0.47 +/- 0.76 -- Acc 0.88\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 391 Loss: 0.51 +/- 0.85 -- Acc 0.85\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 391 Loss: 0.60 +/- 0.89 -- Acc 0.80\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 392 Loss: 0.47 +/- 0.80 -- Acc 0.86\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 392 Loss: 0.36 +/- 0.52 -- Acc 0.90\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 393 Loss: 0.51 +/- 0.83 -- Acc 0.84\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 393 Loss: 0.70 +/- 1.44 -- Acc 0.82\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 394 Loss: 0.47 +/- 0.77 -- Acc 0.86\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 394 Loss: 0.43 +/- 0.67 -- Acc 0.89\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 395 Loss: 0.48 +/- 0.76 -- Acc 0.86\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 395 Loss: 0.50 +/- 0.89 -- Acc 0.87\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 396 Loss: 0.49 +/- 0.78 -- Acc 0.85\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 396 Loss: 0.51 +/- 0.80 -- Acc 0.82\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 397 Loss: 0.51 +/- 0.90 -- Acc 0.85\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 397 Loss: 0.37 +/- 0.51 -- Acc 0.89\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 398 Loss: 0.47 +/- 0.79 -- Acc 0.86\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 398 Loss: 0.30 +/- 0.45 -- Acc 0.93\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 399 Loss: 0.48 +/- 0.84 -- Acc 0.86\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 399 Loss: 0.49 +/- 0.84 -- Acc 0.87\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 400 Loss: 0.46 +/- 0.82 -- Acc 0.87\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 400 Loss: 0.37 +/- 0.55 -- Acc 0.87\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 401 Loss: 0.47 +/- 0.74 -- Acc 0.85\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 401 Loss: 0.45 +/- 0.71 -- Acc 0.88\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 402 Loss: 0.44 +/- 0.72 -- Acc 0.86\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 402 Loss: 0.35 +/- 0.44 -- Acc 0.88\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 403 Loss: 0.43 +/- 0.74 -- Acc 0.89\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 403 Loss: 0.37 +/- 0.59 -- Acc 0.91\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 404 Loss: 0.44 +/- 0.73 -- Acc 0.87\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 404 Loss: 0.43 +/- 0.71 -- Acc 0.88\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 405 Loss: 0.44 +/- 0.74 -- Acc 0.87\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 405 Loss: 0.40 +/- 0.68 -- Acc 0.90\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 406 Loss: 0.43 +/- 0.70 -- Acc 0.87\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 406 Loss: 0.42 +/- 0.64 -- Acc 0.90\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 407 Loss: 0.45 +/- 0.81 -- Acc 0.86\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 407 Loss: 0.42 +/- 0.62 -- Acc 0.89\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 408 Loss: 0.47 +/- 0.77 -- Acc 0.85\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 408 Loss: 0.35 +/- 0.68 -- Acc 0.91\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 409 Loss: 0.48 +/- 0.83 -- Acc 0.86\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 409 Loss: 0.36 +/- 0.57 -- Acc 0.91\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 410 Loss: 0.46 +/- 0.78 -- Acc 0.86\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 410 Loss: 0.47 +/- 0.81 -- Acc 0.83\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 411 Loss: 0.45 +/- 0.76 -- Acc 0.86\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 411 Loss: 0.50 +/- 0.78 -- Acc 0.82\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 412 Loss: 0.43 +/- 0.80 -- Acc 0.87\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 412 Loss: 0.33 +/- 0.53 -- Acc 0.89\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 413 Loss: 0.46 +/- 0.74 -- Acc 0.84\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 413 Loss: 0.37 +/- 0.59 -- Acc 0.90\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 414 Loss: 0.46 +/- 0.79 -- Acc 0.87\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 414 Loss: 0.56 +/- 1.00 -- Acc 0.81\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 415 Loss: 0.45 +/- 0.75 -- Acc 0.86\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 415 Loss: 0.36 +/- 0.47 -- Acc 0.90\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 416 Loss: 0.43 +/- 0.72 -- Acc 0.87\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 416 Loss: 0.50 +/- 0.94 -- Acc 0.86\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 417 Loss: 0.46 +/- 0.81 -- Acc 0.87\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 417 Loss: 0.45 +/- 0.96 -- Acc 0.88\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 418 Loss: 0.46 +/- 0.82 -- Acc 0.86\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 418 Loss: 0.31 +/- 0.46 -- Acc 0.92\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 419 Loss: 0.41 +/- 0.75 -- Acc 0.89\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 419 Loss: 0.50 +/- 1.03 -- Acc 0.87\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 420 Loss: 0.44 +/- 0.76 -- Acc 0.86\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 420 Loss: 0.52 +/- 0.96 -- Acc 0.86\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 421 Loss: 0.46 +/- 0.79 -- Acc 0.87\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 421 Loss: 0.43 +/- 1.15 -- Acc 0.91\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 422 Loss: 0.47 +/- 0.83 -- Acc 0.85\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 422 Loss: 0.31 +/- 0.43 -- Acc 0.89\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 423 Loss: 0.42 +/- 0.72 -- Acc 0.88\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 423 Loss: 0.33 +/- 0.50 -- Acc 0.91\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 424 Loss: 0.43 +/- 0.76 -- Acc 0.86\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 424 Loss: 0.42 +/- 0.79 -- Acc 0.87\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 425 Loss: 0.44 +/- 0.81 -- Acc 0.86\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 425 Loss: 0.43 +/- 0.83 -- Acc 0.91\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 426 Loss: 0.42 +/- 0.74 -- Acc 0.87\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 426 Loss: 0.37 +/- 0.56 -- Acc 0.90\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 427 Loss: 0.39 +/- 0.75 -- Acc 0.88\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 427 Loss: 0.48 +/- 0.74 -- Acc 0.84\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 428 Loss: 0.40 +/- 0.73 -- Acc 0.87\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 428 Loss: 0.32 +/- 0.62 -- Acc 0.91\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 429 Loss: 0.44 +/- 0.78 -- Acc 0.85\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 429 Loss: 0.47 +/- 1.16 -- Acc 0.89\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 430 Loss: 0.44 +/- 0.84 -- Acc 0.87\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 430 Loss: 0.43 +/- 0.64 -- Acc 0.84\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 431 Loss: 0.44 +/- 0.88 -- Acc 0.87\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 431 Loss: 0.37 +/- 0.71 -- Acc 0.90\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 432 Loss: 0.41 +/- 0.76 -- Acc 0.87\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 432 Loss: 0.36 +/- 0.69 -- Acc 0.92\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 433 Loss: 0.39 +/- 0.64 -- Acc 0.87\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 433 Loss: 0.46 +/- 0.90 -- Acc 0.88\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 434 Loss: 0.41 +/- 0.74 -- Acc 0.87\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 434 Loss: 0.29 +/- 0.46 -- Acc 0.97\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 435 Loss: 0.42 +/- 0.76 -- Acc 0.87\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 435 Loss: 0.29 +/- 0.50 -- Acc 0.92\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 436 Loss: 0.43 +/- 0.86 -- Acc 0.88\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 436 Loss: 0.43 +/- 0.71 -- Acc 0.84\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 437 Loss: 0.40 +/- 0.69 -- Acc 0.87\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 437 Loss: 0.39 +/- 0.58 -- Acc 0.87\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 438 Loss: 0.42 +/- 0.72 -- Acc 0.87\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 438 Loss: 0.36 +/- 0.71 -- Acc 0.87\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 439 Loss: 0.37 +/- 0.67 -- Acc 0.89\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 439 Loss: 0.38 +/- 0.63 -- Acc 0.88\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 440 Loss: 0.37 +/- 0.68 -- Acc 0.89\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 440 Loss: 0.40 +/- 0.70 -- Acc 0.87\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 441 Loss: 0.38 +/- 0.71 -- Acc 0.89\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 441 Loss: 0.24 +/- 0.61 -- Acc 0.93\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 442 Loss: 0.41 +/- 0.75 -- Acc 0.88\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 442 Loss: 0.47 +/- 0.73 -- Acc 0.85\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 443 Loss: 0.40 +/- 0.72 -- Acc 0.87\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 443 Loss: 0.41 +/- 0.68 -- Acc 0.88\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 444 Loss: 0.38 +/- 0.75 -- Acc 0.89\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 444 Loss: 0.34 +/- 0.59 -- Acc 0.89\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 445 Loss: 0.41 +/- 0.78 -- Acc 0.87\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 445 Loss: 0.37 +/- 0.55 -- Acc 0.90\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 446 Loss: 0.44 +/- 0.78 -- Acc 0.86\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 446 Loss: 0.30 +/- 0.53 -- Acc 0.91\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 447 Loss: 0.42 +/- 0.77 -- Acc 0.87\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 447 Loss: 0.36 +/- 0.84 -- Acc 0.91\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 448 Loss: 0.39 +/- 0.72 -- Acc 0.87\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 448 Loss: 0.27 +/- 0.44 -- Acc 0.92\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 449 Loss: 0.39 +/- 0.75 -- Acc 0.88\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 449 Loss: 0.27 +/- 0.49 -- Acc 0.93\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 450 Loss: 0.35 +/- 0.72 -- Acc 0.90\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 450 Loss: 0.28 +/- 0.52 -- Acc 0.93\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 451 Loss: 0.40 +/- 0.75 -- Acc 0.87\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 451 Loss: 0.47 +/- 1.18 -- Acc 0.89\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 452 Loss: 0.37 +/- 0.66 -- Acc 0.88\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 452 Loss: 0.29 +/- 0.58 -- Acc 0.91\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 453 Loss: 0.38 +/- 0.71 -- Acc 0.88\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 453 Loss: 0.38 +/- 0.69 -- Acc 0.85\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 454 Loss: 0.39 +/- 0.73 -- Acc 0.88\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 454 Loss: 0.24 +/- 0.41 -- Acc 0.92\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 455 Loss: 0.37 +/- 0.71 -- Acc 0.88\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 455 Loss: 0.28 +/- 0.50 -- Acc 0.90\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 456 Loss: 0.37 +/- 0.65 -- Acc 0.88\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 456 Loss: 0.33 +/- 0.61 -- Acc 0.90\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 457 Loss: 0.38 +/- 0.75 -- Acc 0.89\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 457 Loss: 0.33 +/- 0.56 -- Acc 0.90\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 458 Loss: 0.39 +/- 0.77 -- Acc 0.89\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 458 Loss: 0.39 +/- 0.84 -- Acc 0.86\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 459 Loss: 0.40 +/- 0.75 -- Acc 0.88\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 459 Loss: 0.32 +/- 0.61 -- Acc 0.90\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 460 Loss: 0.39 +/- 0.75 -- Acc 0.89\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 460 Loss: 0.36 +/- 0.62 -- Acc 0.87\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 461 Loss: 0.36 +/- 0.73 -- Acc 0.89\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 461 Loss: 0.41 +/- 0.76 -- Acc 0.84\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 462 Loss: 0.37 +/- 0.71 -- Acc 0.89\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 462 Loss: 0.31 +/- 0.48 -- Acc 0.89\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 463 Loss: 0.40 +/- 0.78 -- Acc 0.88\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 463 Loss: 0.35 +/- 0.66 -- Acc 0.90\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 464 Loss: 0.37 +/- 0.72 -- Acc 0.88\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 464 Loss: 0.36 +/- 0.74 -- Acc 0.92\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 465 Loss: 0.39 +/- 0.87 -- Acc 0.89\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 465 Loss: 0.22 +/- 0.43 -- Acc 0.94\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 466 Loss: 0.34 +/- 0.65 -- Acc 0.90\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 466 Loss: 0.30 +/- 0.80 -- Acc 0.93\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 467 Loss: 0.36 +/- 0.72 -- Acc 0.89\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 467 Loss: 0.36 +/- 0.53 -- Acc 0.88\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 468 Loss: 0.35 +/- 0.75 -- Acc 0.90\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 468 Loss: 0.47 +/- 1.14 -- Acc 0.91\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 469 Loss: 0.39 +/- 0.81 -- Acc 0.88\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 469 Loss: 0.31 +/- 0.57 -- Acc 0.91\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 470 Loss: 0.37 +/- 0.76 -- Acc 0.89\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 470 Loss: 0.32 +/- 0.63 -- Acc 0.91\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 471 Loss: 0.37 +/- 0.75 -- Acc 0.89\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 471 Loss: 0.35 +/- 0.74 -- Acc 0.92\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 472 Loss: 0.37 +/- 0.70 -- Acc 0.88\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 472 Loss: 0.31 +/- 0.51 -- Acc 0.89\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 473 Loss: 0.34 +/- 0.66 -- Acc 0.90\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 473 Loss: 0.30 +/- 0.53 -- Acc 0.94\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 474 Loss: 0.36 +/- 0.76 -- Acc 0.89\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 474 Loss: 0.30 +/- 0.57 -- Acc 0.90\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 475 Loss: 0.34 +/- 0.72 -- Acc 0.90\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 475 Loss: 0.38 +/- 0.69 -- Acc 0.91\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 476 Loss: 0.39 +/- 0.83 -- Acc 0.89\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 476 Loss: 0.34 +/- 0.58 -- Acc 0.88\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 477 Loss: 0.39 +/- 0.79 -- Acc 0.88\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 477 Loss: 0.35 +/- 0.68 -- Acc 0.92\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 478 Loss: 0.40 +/- 0.87 -- Acc 0.89\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 478 Loss: 0.37 +/- 0.70 -- Acc 0.90\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 479 Loss: 0.33 +/- 0.68 -- Acc 0.90\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 479 Loss: 0.27 +/- 0.54 -- Acc 0.93\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 480 Loss: 0.40 +/- 0.82 -- Acc 0.89\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 480 Loss: 0.25 +/- 0.53 -- Acc 0.96\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 481 Loss: 0.36 +/- 0.72 -- Acc 0.88\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 481 Loss: 0.34 +/- 0.58 -- Acc 0.91\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 482 Loss: 0.36 +/- 0.74 -- Acc 0.89\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 482 Loss: 0.47 +/- 1.08 -- Acc 0.89\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 483 Loss: 0.35 +/- 0.70 -- Acc 0.89\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 483 Loss: 0.36 +/- 0.73 -- Acc 0.89\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 484 Loss: 0.35 +/- 0.73 -- Acc 0.90\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 484 Loss: 0.25 +/- 0.41 -- Acc 0.91\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 485 Loss: 0.40 +/- 0.84 -- Acc 0.87\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 485 Loss: 0.27 +/- 0.62 -- Acc 0.93\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 486 Loss: 0.32 +/- 0.67 -- Acc 0.91\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 486 Loss: 0.30 +/- 0.51 -- Acc 0.91\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 487 Loss: 0.32 +/- 0.64 -- Acc 0.90\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 487 Loss: 0.32 +/- 0.67 -- Acc 0.91\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 488 Loss: 0.35 +/- 0.71 -- Acc 0.89\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 488 Loss: 0.32 +/- 0.64 -- Acc 0.90\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 489 Loss: 0.38 +/- 0.77 -- Acc 0.88\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 489 Loss: 0.19 +/- 0.32 -- Acc 0.97\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 490 Loss: 0.35 +/- 0.73 -- Acc 0.89\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 490 Loss: 0.31 +/- 0.48 -- Acc 0.88\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 491 Loss: 0.39 +/- 0.78 -- Acc 0.87\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 491 Loss: 0.25 +/- 0.46 -- Acc 0.91\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 492 Loss: 0.35 +/- 0.74 -- Acc 0.90\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 492 Loss: 0.21 +/- 0.40 -- Acc 0.96\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 493 Loss: 0.31 +/- 0.65 -- Acc 0.91\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 493 Loss: 0.21 +/- 0.39 -- Acc 0.97\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 494 Loss: 0.29 +/- 0.64 -- Acc 0.91\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 494 Loss: 0.20 +/- 0.38 -- Acc 0.97\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 495 Loss: 0.35 +/- 0.71 -- Acc 0.89\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 495 Loss: 0.24 +/- 0.56 -- Acc 0.96\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 496 Loss: 0.40 +/- 0.84 -- Acc 0.89\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 496 Loss: 0.21 +/- 0.36 -- Acc 0.94\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 497 Loss: 0.34 +/- 0.69 -- Acc 0.89\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 497 Loss: 0.38 +/- 0.73 -- Acc 0.89\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 498 Loss: 0.34 +/- 0.69 -- Acc 0.90\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 498 Loss: 0.35 +/- 0.61 -- Acc 0.86\n",
            "\n",
            " *************** Training ***************\n",
            "Epoch: 499 Loss: 0.34 +/- 0.67 -- Acc 0.90\n",
            "\n",
            " *************** Validation ***************\n",
            "Epoch: 499 Loss: 0.24 +/- 0.42 -- Acc 0.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convergence Analysis"
      ],
      "metadata": {
        "id": "YZ7pHSD-c2eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15, 4))\n",
        "\n",
        "ax1.plot(train_loss[1:], label = 'Train')\n",
        "ax1.plot(validation_loss[1:], label = 'Validation')\n",
        "ax1.set_title('Model Convergence - Loss')\n",
        "ax1.set_xlabel('Epochs')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.legend()\n",
        "\n",
        "ax2.plot(train_accuracy, label = 'Train')\n",
        "ax2.plot(validation_accuracy, label = 'Validation')\n",
        "ax2.set_title('Model Convergence - Accuracy')\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax2.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "6Ta5Fp7gaMzT",
        "outputId": "25ee1f39-a045-4f54-c3f5-db696c2659af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7dd20c34ebf0>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the template"
      ],
      "metadata": {
        "id": "DCiLlAcvgZiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(name):\n",
        "  net.eval()\n",
        "\n",
        "  tns = torch.zeros( len(name), size_dictionary )\n",
        "  for k, letter in enumerate(name):\n",
        "    idx = valid_characters.find(letter)\n",
        "    tns[k, idx] = 1\n",
        "  tns = tns.to(args['device'])\n",
        "\n",
        "  out = net(tns)\n",
        "  topv, topi = out.data.topk(3, 1, True)\n",
        "\n",
        "  print(name)\n",
        "  for value, index in zip(topv[0], topi[0]):\n",
        "    print('(%.2f) %s' % (value, categories[index]))\n",
        "  print('\\n')\n",
        "\n",
        "predict('Merkel')\n",
        "predict('Hirobumi')\n",
        "predict('Suarez')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lanz1xitgJ8c",
        "outputId": "80b85481-9395-4cc5-c374-6dd118ab85da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merkel\n",
            "(-1.02) German\n",
            "(-1.26) English\n",
            "(-1.58) Dutch\n",
            "\n",
            "\n",
            "Hirobumi\n",
            "(-0.03) Japanese\n",
            "(-3.75) Russian\n",
            "(-6.92) German\n",
            "\n",
            "\n",
            "Suarez\n",
            "(-0.04) Spanish\n",
            "(-4.30) Polish\n",
            "(-4.61) Dutch\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QkaOURiggfut"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}